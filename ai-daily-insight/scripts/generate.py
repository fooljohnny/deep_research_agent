"""
generate.py â€” Stage-2 prompt: turn structural analysis into a Markdown insight post.

Takes the five-dimension structural change JSON from Stage-1 and asks the
LLM to produce a Markdown blog post focused on *structural shifts*, not
news summaries.
"""

import logging
from datetime import datetime, timezone
from pathlib import Path
from typing import Any
import json

from llm_client import get_client, get_model

logger = logging.getLogger(__name__)

CONTENT_DIR = Path(__file__).resolve().parent.parent / "content"

SYSTEM_PROMPT = """\
ä½ æ˜¯ä¸€ä½AIäº§ä¸šç»“æ„æ´å¯Ÿåšä¸»ï¼Œæ¯å¤©å‘å¸ƒä¸€ç¯‡ç»“æ„æ€§å˜åŒ–åˆ†æã€‚

ä½ å°†æ”¶åˆ°ä¸€ä»½ç»“æ„åŒ–JSONåˆ†æï¼ˆåŒ…å«äº”ä¸ªç»´åº¦ï¼šæŠ€æœ¯å±‚ã€åŸºç¡€è®¾æ–½ã€åº”ç”¨å±‚ã€èµ„æœ¬ä¿¡å·ã€é£é™©ä¿¡å·ï¼‰ã€‚

è¯·å°†å…¶è½¬åŒ–ä¸ºä¸€ç¯‡é«˜è´¨é‡çš„ Markdown åšå®¢æ–‡ç« ã€‚

### å†™ä½œåŸåˆ™
- è¿™ä¸æ˜¯æ–°é—»æ‘˜è¦ï¼Œè€Œæ˜¯ç»“æ„æ€§å˜åŒ–æ´å¯Ÿã€‚
- æ ¸å¿ƒé—®é¢˜æ˜¯ï¼šä»Šå¤©çš„ä¿¡æ¯æ„å‘³ç€AIäº§ä¸šæ ¼å±€å‘ç”Ÿäº†ä»€ä¹ˆå˜åŒ–ï¼Ÿ
- æœ‰å˜åŒ–çš„ç»´åº¦æ·±å…¥å±•å¼€ï¼Œæ— å˜åŒ–çš„ç»´åº¦ä¸€ç¬”å¸¦è¿‡ã€‚
- è¯­è¨€è¦çŠ€åˆ©ã€æœ‰è§‚ç‚¹ã€ä¸åºŸè¯ã€‚
- ç”¨ä¸­æ–‡æ’°å†™ã€‚

### æ ¼å¼è¦æ±‚
- ä»¥ YAML front-matter å¼€å¤´ï¼ˆtitle, date, tagsï¼‰ã€‚
- ç¬¬ä¸€æ®µæ˜¯"ä»Šæ—¥æ ¸å¿ƒåˆ¤æ–­"ï¼ˆcore_insightï¼‰ï¼Œç”¨å¼•ç”¨å—æ ¼å¼ï¼ˆ> ï¼‰ã€‚
- ç„¶åæŒ‰äº”ä¸ªç»´åº¦åˆ†èŠ‚ï¼Œä½¿ç”¨ ## æ ‡é¢˜ï¼š
  - æŠ€æœ¯å±‚ï¼šæ¨¡å‹èƒ½åŠ›ä¸æ–°èŒƒå¼
  - åŸºç¡€è®¾æ–½å±‚ï¼šæ¨ç†æˆæœ¬ä¸ç®—åŠ›
  - åº”ç”¨å±‚ï¼šåœºæ™¯æ‰©å±•ä¸æ›¿ä»£æ•ˆåº”
  - èµ„æœ¬ä¿¡å·ï¼šèèµ„ä¸æˆ˜ç•¥
  - é£é™©ä¿¡å·ï¼šç›‘ç®¡ä¸ä¼¦ç†
- æ¯ä¸ªç»´åº¦å¼€å¤´æ ‡æ³¨å˜åŒ–å¼ºåº¦æ ‡ç­¾ï¼Œä¾‹å¦‚ï¼š`ğŸ”´ é‡å¤§çªç ´` `ğŸŸ¡ æ¸è¿›æ”¹å–„` `âšª æ— æ˜¾è‘—å˜åŒ–` `ğŸ”´ å¼ºä¿¡å·` `ğŸŸ¡ ä¸­ç­‰ä¿¡å·` `âšª å¼±ä¿¡å·`
- æœ‰å˜åŒ–çš„ç»´åº¦ï¼šåˆ†æå˜åŒ–æœ¬è´¨ + å¼•ç”¨è¯æ®æ–‡ç« ï¼ˆå«é“¾æ¥ï¼‰ã€‚
- æ— å˜åŒ–çš„ç»´åº¦ï¼šç®€çŸ­è¯´æ˜å³å¯ï¼ˆ1-2å¥è¯ï¼‰ã€‚
- æœ€åä¸€èŠ‚ ## å€¼å¾—å…³æ³¨çš„é“¾æ¥ï¼šåˆ—å‡ºåˆ†æä¸­å¼•ç”¨çš„å…³é”®æ–‡ç« é“¾æ¥ã€‚
- æ€»å­—æ•°æ§åˆ¶åœ¨ 800-1500 å­—ã€‚
"""


def _build_user_prompt(analysis: dict[str, Any]) -> str:
    return (
        "ä»¥ä¸‹æ˜¯ä»Šæ—¥çš„ç»“æ„æ€§å˜åŒ–åˆ†æJSONï¼Œè¯·æŒ‰ç…§è§„åˆ™å°†å…¶è½¬åŒ–ä¸ºMarkdownåšå®¢æ–‡ç« ã€‚\n\n"
        + json.dumps(analysis, indent=2, ensure_ascii=False)
    )


def generate_post(analysis: dict[str, Any]) -> str:
    """
    Stage-2 generation: structural analysis JSON â†’ Markdown blog post.

    Returns the Markdown string and writes it to content/<date>.md.
    """
    client = get_client()
    model = get_model()

    user_prompt = _build_user_prompt(analysis)
    logger.info("Sending analysis to LLM (%s) for Stage-2 generation â€¦", model)

    response = client.chat.completions.create(
        model=model,
        temperature=0.5,
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": user_prompt},
        ],
    )

    markdown: str = response.choices[0].message.content or ""

    today = datetime.now(timezone.utc).strftime("%Y-%m-%d")
    CONTENT_DIR.mkdir(parents=True, exist_ok=True)
    out_path = CONTENT_DIR / f"{today}.md"
    out_path.write_text(markdown, encoding="utf-8")
    logger.info("Blog post written to %s (%d chars)", out_path, len(markdown))

    return markdown


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    sample_analysis = {
        "date": "2026-02-26",
        "title": "AgentèŒƒå¼åŠ é€Ÿè½åœ°ï¼Œèµ„æœ¬å¯†é›†æ¶Œå…¥AIåŸºç¡€è®¾æ–½",
        "core_insight": "AI Agentä»æ¦‚å¿µéªŒè¯è¿›å…¥äº§ä¸šçº§éƒ¨ç½²ï¼ŒåŸºç¡€è®¾æ–½å±‚èèµ„å¯†åº¦åˆ›å­£åº¦æ–°é«˜ã€‚",
        "dimensions": {
            "technology": {
                "has_change": True,
                "intensity": "æ¸è¿›æ”¹å–„",
                "model_capability": "å¤šä¸ªå¼€æºæ¨¡å‹åœ¨æ¨ç†èƒ½åŠ›ä¸Šé€¼è¿‘é—­æºå‰æ²¿ã€‚",
                "new_paradigm": "Agentç¼–æ’æ¡†æ¶è¶‹äºæ ‡å‡†åŒ–ã€‚",
                "evidence": [
                    {"title": "Sample Paper", "source": "arXiv cs.AI", "url": "https://arxiv.org/example"}
                ],
            },
            "infrastructure": {
                "has_change": True,
                "intensity": "é‡å¤§çªç ´",
                "inference_cost": "æ–°ä¸€ä»£æ¨ç†èŠ¯ç‰‡å°†å•ä½æˆæœ¬é™ä½40%ã€‚",
                "compute_trend": "äº‘å‚å•†å¼€å§‹æä¾›Agentä¸“ç”¨ç®—åŠ›å®ä¾‹ã€‚",
                "evidence": [
                    {"title": "Sample Infra News", "source": "TechCrunch AI", "url": "https://techcrunch.com/example"}
                ],
            },
            "application": {
                "has_change": False,
                "intensity": "æ— æ˜¾è‘—å˜åŒ–",
                "new_industries": "ä»Šæ—¥æ— æ–°è¡Œä¸šæ¸—é€ä¿¡å·ã€‚",
                "displacement": "ä»Šæ—¥æ— æ˜¾è‘—æ›¿ä»£æ¡ˆä¾‹ã€‚",
                "evidence": [],
            },
            "capital": {
                "has_change": True,
                "intensity": "å¼ºä¿¡å·",
                "funding_trend": "åŸºç¡€è®¾æ–½èµ›é“æœ¬å‘¨ç¬¬ä¸‰ç¬”å¤§é¢èèµ„ã€‚",
                "valuation": "å¤´éƒ¨AIå…¬å¸ä¼°å€¼ç»§ç»­ä¸Šè¡Œã€‚",
                "strategic_moves": "æŸå¤§å‚æ”¶è´­æ¨ç†ä¼˜åŒ–åˆ›ä¸šå…¬å¸ã€‚",
                "evidence": [
                    {"title": "Sample Funding", "source": "Crunchbase News", "url": "https://crunchbase.com/example"}
                ],
            },
            "risk": {
                "has_change": False,
                "intensity": "å¼±ä¿¡å·",
                "regulation": "ä»Šæ—¥æ— æ–°ç›‘ç®¡åŠ¨å‘ã€‚",
                "ethics_safety": "ä»Šæ—¥æ— æ–°ä¼¦ç†äº‰è®®ã€‚",
                "supply_chain": "ä»Šæ—¥æ— ä¾›åº”é“¾å˜åŒ–ã€‚",
                "evidence": [],
            },
        },
    }
    md = generate_post(sample_analysis)
    print(md)
