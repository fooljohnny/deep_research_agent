"""
generate.py â€” Stage-2 prompt: turn structural analysis + trend signals
into a professional AI industry insight blog post.

Takes the five-dimension structural change JSON from Stage-1 and the
trend comparison report, then asks the LLM to produce a Markdown blog
with a fixed six-section structure focused on structural shifts.
"""

import logging
from datetime import datetime, timezone
from pathlib import Path
from typing import Any
import json

from llm_client import get_client, get_model

logger = logging.getLogger(__name__)

CONTENT_DIR = Path(__file__).resolve().parent.parent / "content"

SYSTEM_PROMPT = """\
ä½ æ˜¯ä¸€ä½é¡¶çº§AIäº§ä¸šç»“æ„åˆ†æå¸ˆï¼Œæ¯å¤©å‘å¸ƒä¸€ç¯‡æ·±åº¦æ´å¯Ÿåšå®¢ã€‚

ä½ å°†æ”¶åˆ°ä¸¤ä»½æ•°æ®ï¼š
1. **ä»Šæ—¥ç»“æ„åˆ†æJSON**ï¼šäº”ä¸ªç»´åº¦çš„ç»“æ„æ€§å˜åŒ–åˆ†æ
2. **è¶‹åŠ¿å¯¹æ¯”æŠ¥å‘ŠJSON**ï¼šä»Šæ—¥è¯é¢˜å‘é‡ä¸è¿‡å»30å¤©çš„å¯¹æ¯”ç»“æœ

### æ ¸å¿ƒåŸåˆ™
- è¿™ä¸æ˜¯æ–°é—»æ‘˜è¦ï¼Œè€Œæ˜¯**ç»“æ„æ€§å˜åŒ–æ´å¯Ÿ**ã€‚
- æ¯ä¸€æ®µæ–‡å­—éƒ½è¦å›ç­”ï¼š"è¿™æ„å‘³ç€AIäº§ä¸šæ ¼å±€å‘ç”Ÿäº†ä»€ä¹ˆå˜åŒ–ï¼Ÿ"
- ä¸è¦ç½—åˆ—æ–°é—»ï¼Œè¦æç‚¼ä¿¡å·ã€åˆ¤æ–­æ‹ç‚¹ã€ç»™å‡ºè§‚ç‚¹ã€‚
- è¯­è¨€çŠ€åˆ©ã€ä¸“ä¸šã€æœ‰åˆ¤æ–­åŠ›ã€‚ä¸è¯´åºŸè¯ï¼Œä¸å †ç Œå½¢å®¹è¯ã€‚
- ç”¨ä¸­æ–‡æ’°å†™ã€‚

### åšå®¢ç»“æ„ï¼ˆä¸¥æ ¼éµå®ˆä»¥ä¸‹å…­èŠ‚ï¼‰

#### Front-matter
ä»¥ YAML front-matter å¼€å¤´ï¼š
```
---
title: "æ ‡é¢˜"
date: YYYY-MM-DD
tags: [å…³é”®æ ‡ç­¾]
---
```

#### # ä»Šæ—¥AIç»“æ„æ€§å˜åŒ–
- ç”¨ `> ` å¼•ç”¨å—å†™å‡ºä»Šæ—¥æ ¸å¿ƒåˆ¤æ–­ï¼ˆä¸€å¥è¯ï¼‰ã€‚
- ç´§è·Ÿ 2-3 å¥è¯å±•å¼€ï¼šä»Šå¤©æœ€å€¼å¾—æ³¨æ„çš„ç»“æ„æ€§å˜åŒ–æ˜¯ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆé‡è¦ï¼Ÿ
- å¦‚æœè¶‹åŠ¿æŠ¥å‘Šä¸­æœ‰ä¿¡å·ï¼ˆçªç„¶å¢å¼º/æŒç»­è¶‹åŠ¿/æ–°å…´è¯é¢˜ï¼‰ï¼Œåœ¨è¿™é‡Œç”¨ç®€æ´çš„åˆ—è¡¨
  æ ‡æ³¨å‡ºæ¥ï¼Œä¾‹å¦‚ï¼š
  - ğŸ“ˆ **æŒç»­è¶‹åŠ¿**ï¼šæŠ€æœ¯å±‚è¯é¢˜å·²è¿ç»­Nå¤©å¢å¼º
  - ğŸ†• **æ–°å…´æ–¹å‘**ï¼šæŸè¯é¢˜ä¸º30å¤©å†…é¦–æ¬¡å‡ºç°
  - ğŸ”º **çªç„¶å‡æ¸©**ï¼šæŸæ–¹å‘è¿‘3å¤©çªç„¶é›†ä¸­å‡ºç°
  - ğŸ”‘ **æ–°å…³é”®è¯**ï¼šxxx, yyy
  - ğŸ“‰ **æ¶ˆé€€å…³é”®è¯**ï¼šzzz

#### # æŠ€æœ¯å±‚ä¿¡å·
- å˜åŒ–å¼ºåº¦æ ‡ç­¾å¼€å¤´ï¼š`ğŸ”´ é‡å¤§çªç ´` / `ğŸŸ¡ æ¸è¿›æ”¹å–„` / `âšª æ— æ˜¾è‘—å˜åŒ–`
- å›ç­”ä¸¤ä¸ªé—®é¢˜ï¼š
  1. æ¨¡å‹èƒ½åŠ›è¾¹ç•Œæ˜¯å¦è¢«æ¨è¿›ï¼Ÿæ€ä¹ˆæ¨è¿›çš„ï¼Ÿ
  2. æ˜¯å¦å‡ºç°æ–°èŒƒå¼ï¼Ÿä¸ºä»€ä¹ˆå®ƒé‡è¦ï¼Ÿ
- å¼•ç”¨è¯æ®æ–‡ç« ï¼ˆå«æ ‡é¢˜å’Œé“¾æ¥ï¼‰ã€‚
- å¦‚æœè¶‹åŠ¿æŠ¥å‘Šæ˜¾ç¤ºè¯¥ç»´åº¦æœ‰è¶‹åŠ¿ä¿¡å·ï¼Œä½“ç°å†å²å¯¹æ¯”è§†è§’ã€‚
- æ— å˜åŒ–æ—¶ 1-2 å¥è¯å¸¦è¿‡ã€‚

#### # äº§ä¸šèµ„æœ¬ä¿¡å·
- å˜åŒ–å¼ºåº¦æ ‡ç­¾å¼€å¤´ï¼š`ğŸ”´ å¼ºä¿¡å·` / `ğŸŸ¡ ä¸­ç­‰ä¿¡å·` / `âšª å¼±ä¿¡å·`
- èåˆä¸‰ä¸ªå­ç»´åº¦è¿›è¡Œåˆ†æï¼š
  - **åŸºç¡€è®¾æ–½å˜åŒ–**ï¼šæ¨ç†æˆæœ¬ã€èŠ¯ç‰‡/ç®—åŠ›è¶‹åŠ¿
  - **åº”ç”¨å±‚å˜åŒ–**ï¼šæ–°è¡Œä¸šæ¸—é€ã€æ›¿ä»£æ—§æ–¹æ¡ˆ
  - **èµ„æœ¬æµå‘**ï¼šèèµ„é›†ä¸­æ–¹å‘ã€ä¼°å€¼å˜åŒ–ã€å¤§å‚æˆ˜ç•¥æŠ•èµ„/æ”¶è´­
- é‡ç‚¹æ˜¯ï¼š**é’±åœ¨å¾€å“ªé‡Œæµï¼ŸåŸºç¡€è®¾æ–½åœ¨æ€ä¹ˆå˜ï¼Ÿåº”ç”¨åœ¨å“ªé‡Œè½åœ°ï¼Ÿ**
  è¿™ä¸‰è€…åˆåœ¨ä¸€èµ·æ„æˆå®Œæ•´çš„äº§ä¸šèµ„æœ¬å›¾æ™¯ã€‚
- å¼•ç”¨è¯æ®æ–‡ç« ã€‚
- æ— å˜åŒ–æ—¶ç®€çŸ­è¯´æ˜ã€‚

#### # æ½œåœ¨æ‹ç‚¹åˆ¤æ–­
- åŸºäºä»Šæ—¥ä¿¡å· + å†å²è¶‹åŠ¿ï¼Œåˆ¤æ–­æ˜¯å¦å­˜åœ¨æ½œåœ¨æ‹ç‚¹ã€‚
- æ‹ç‚¹ = æŸä¸ªæ–¹å‘å¯èƒ½å³å°†å‘ç”Ÿè´¨å˜çš„è½¬æŠ˜ç‚¹ã€‚
- å¦‚æœæœ‰æ‹ç‚¹ä¿¡å·ï¼Œè¯´æ˜ï¼š
  - æ˜¯ä»€ä¹ˆæ‹ç‚¹ï¼Ÿ
  - ä¾æ®æ˜¯ä»€ä¹ˆï¼Ÿï¼ˆä»Šæ—¥ä¿¡å· + å†å²è¶‹åŠ¿ï¼‰
  - å¦‚æœå‘ç”Ÿï¼Œå½±å“æ˜¯ä»€ä¹ˆï¼Ÿ
- å¦‚æœä»Šæ—¥æ²¡æœ‰æ‹ç‚¹ä¿¡å·ï¼Œä¹Ÿè¦æ˜ç¡®è¯´æ˜"ä»Šæ—¥æœªè§‚å¯Ÿåˆ°æ‹ç‚¹ä¿¡å·"å¹¶ç®€è¿°åŸå› ã€‚

#### # æ˜æ—¥è§‚å¯Ÿç‚¹
- åˆ—å‡º 2-3 ä¸ªæ˜å¤©å€¼å¾—é‡ç‚¹å…³æ³¨çš„æ–¹å‘ã€‚
- æ¯ä¸ªè§‚å¯Ÿç‚¹è¯´æ˜ï¼šå…³æ³¨ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆï¼Ÿæ€ä¹ˆåˆ¤æ–­æ˜¯å¦å‘ç”Ÿå˜åŒ–ï¼Ÿ
- æ ¼å¼ç”¨ç¼–å·åˆ—è¡¨ã€‚

#### # é•¿æœŸè¶‹åŠ¿åæ ‡
- å°†ä»Šæ—¥è§‚å¯Ÿæ”¾å…¥æ›´å¤§çš„æ—¶é—´æ¡†æ¶ï¼ˆæœˆåº¦/å­£åº¦çº§åˆ«ï¼‰ã€‚
- å›ç­”ï¼šä»Šå¤©çš„ä¿¡å·åœ¨ AI äº§ä¸šæ¼”è¿›çš„å¤§å›¾ä¸­å¤„äºä»€ä¹ˆä½ç½®ï¼Ÿ
- ç”¨ 1-2 æ®µè¯æ”¶å°¾ï¼Œç»™å‡ºç»“æ„æ€§åˆ¤æ–­ã€‚
- å¦‚æœè¶‹åŠ¿æŠ¥å‘Šæœ‰ overall_novelty æˆ– keyword_trends æ•°æ®ï¼Œ
  åœ¨è¿™é‡Œå¼•ç”¨ä½œä¸º"åæ ‡æ„Ÿ"çš„ä¾æ®ã€‚

### é£æ ¼è¦æ±‚
- æ€»å­—æ•°ï¼š1000-1800å­—ã€‚
- æœ‰å˜åŒ–çš„æ–¹å‘é‡ç‚¹å±•å¼€ï¼Œæ— å˜åŒ–çš„æ–¹å‘å¿«é€Ÿå¸¦è¿‡ã€‚
- æ¯ä¸ªå¼•ç”¨çš„æ–‡ç« ç”¨ `[æ ‡é¢˜](é“¾æ¥)` æ ¼å¼ã€‚
- ä¸è¦åœ¨æ–‡æœ«å•ç‹¬åˆ—é“¾æ¥åˆ—è¡¨â€”â€”é“¾æ¥åœ¨è¡Œæ–‡ä¸­è‡ªç„¶å¼•ç”¨å³å¯ã€‚
"""


def _build_user_prompt(
    analysis: dict[str, Any],
    trend_report: dict[str, Any] | None = None,
) -> str:
    parts = [
        "## ä»Šæ—¥ç»“æ„åˆ†æ\n",
        json.dumps(analysis, indent=2, ensure_ascii=False),
    ]

    if trend_report and trend_report.get("has_enough_history"):
        parts.append("\n\n## è¶‹åŠ¿å¯¹æ¯”æŠ¥å‘Š\n")
        parts.append(json.dumps(trend_report, indent=2, ensure_ascii=False))
    elif trend_report:
        parts.append(
            f"\n\n## è¶‹åŠ¿å¯¹æ¯”\n{trend_report.get('message', 'å†å²æ•°æ®ä¸è¶³ï¼Œæš‚æ— è¶‹åŠ¿åˆ†æã€‚')}"
        )

    return "\n".join(parts)


def generate_post(
    analysis: dict[str, Any],
    trend_report: dict[str, Any] | None = None,
) -> str:
    """
    Stage-2 generation: analysis + trends â†’ Markdown insight blog post.

    Returns the Markdown string and writes it to content/<date>.md.
    """
    client = get_client()
    model = get_model()

    user_prompt = _build_user_prompt(analysis, trend_report)
    logger.info("Sending analysis + trends to LLM (%s) for Stage-2 generation â€¦", model)

    response = client.chat.completions.create(
        model=model,
        temperature=0.5,
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": user_prompt},
        ],
    )

    markdown: str = response.choices[0].message.content or ""

    today = datetime.now(timezone.utc).strftime("%Y-%m-%d")
    CONTENT_DIR.mkdir(parents=True, exist_ok=True)
    out_path = CONTENT_DIR / f"{today}.md"
    out_path.write_text(markdown, encoding="utf-8")
    logger.info("Blog post written to %s (%d chars)", out_path, len(markdown))

    return markdown


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    sample_analysis = {
        "date": "2026-02-26",
        "title": "AgentèŒƒå¼åŠ é€Ÿè½åœ°ï¼Œèµ„æœ¬å¯†é›†æ¶Œå…¥AIåŸºç¡€è®¾æ–½",
        "core_insight": "AI Agentä»æ¦‚å¿µéªŒè¯è¿›å…¥äº§ä¸šçº§éƒ¨ç½²ï¼ŒåŸºç¡€è®¾æ–½å±‚èèµ„å¯†åº¦åˆ›å­£åº¦æ–°é«˜ã€‚",
        "keywords": ["agent", "infrastructure", "RAG", "inference"],
        "dimensions": {
            "technology": {
                "has_change": True,
                "intensity": "æ¸è¿›æ”¹å–„",
                "model_capability": "å¤šä¸ªå¼€æºæ¨¡å‹åœ¨æ¨ç†èƒ½åŠ›ä¸Šé€¼è¿‘é—­æºå‰æ²¿ã€‚",
                "new_paradigm": "Agentç¼–æ’æ¡†æ¶è¶‹äºæ ‡å‡†åŒ–ã€‚",
                "evidence": [
                    {"title": "Sample Paper", "source": "arXiv cs.AI", "url": "https://arxiv.org/example"}
                ],
            },
            "infrastructure": {
                "has_change": True,
                "intensity": "é‡å¤§çªç ´",
                "inference_cost": "æ–°ä¸€ä»£æ¨ç†èŠ¯ç‰‡å°†å•ä½æˆæœ¬é™ä½40%ã€‚",
                "compute_trend": "äº‘å‚å•†å¼€å§‹æä¾›Agentä¸“ç”¨ç®—åŠ›å®ä¾‹ã€‚",
                "evidence": [
                    {"title": "Sample Infra", "source": "TechCrunch AI", "url": "https://techcrunch.com/example"}
                ],
            },
            "application": {
                "has_change": False, "intensity": "æ— æ˜¾è‘—å˜åŒ–",
                "new_industries": "", "displacement": "", "evidence": [],
            },
            "capital": {
                "has_change": True, "intensity": "å¼ºä¿¡å·",
                "funding_trend": "åŸºç¡€è®¾æ–½èµ›é“æœ¬å‘¨ç¬¬ä¸‰ç¬”å¤§é¢èèµ„ã€‚",
                "valuation": "å¤´éƒ¨AIå…¬å¸ä¼°å€¼ç»§ç»­ä¸Šè¡Œã€‚",
                "strategic_moves": "æŸå¤§å‚æ”¶è´­æ¨ç†ä¼˜åŒ–åˆ›ä¸šå…¬å¸ã€‚",
                "evidence": [
                    {"title": "Sample Funding", "source": "Crunchbase News", "url": "https://crunchbase.com/example"}
                ],
            },
            "risk": {
                "has_change": False, "intensity": "å¼±ä¿¡å·",
                "regulation": "", "ethics_safety": "", "supply_chain": "", "evidence": [],
            },
        },
    }
    sample_trends = {
        "has_enough_history": True,
        "history_days": 15,
        "overall_novelty": 0.35,
        "signals": [
            {
                "type": "continuous_trend",
                "dimension": "æŠ€æœ¯å±‚",
                "description": "æŠ€æœ¯å±‚è¯é¢˜å‘é‡åœ¨æœ€è¿‘7å¤©å†…æŒç»­å¢å¼ºã€‚",
                "trend_days": 7,
                "confidence": 0.80,
            },
            {
                "type": "emerging_topic",
                "dimension": "åŸºç¡€è®¾æ–½",
                "description": "åŸºç¡€è®¾æ–½å‡ºç°å…¨æ–°è¯é¢˜ï¼ˆnovelty 0.95ï¼‰ã€‚",
                "novelty_score": 0.95,
                "confidence": 0.95,
            },
        ],
        "keyword_trends": {
            "new_keywords": ["agent-orchestration"],
            "rising_keywords": ["inference", "RAG"],
            "fading_keywords": ["diffusion"],
        },
    }
    md = generate_post(sample_analysis, sample_trends)
    print(md)
