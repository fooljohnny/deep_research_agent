"""
generate.py â€” Stage-2 prompt: turn structural analysis + trend signals
into a professional AI industry insight blog post.

Takes the five-dimension structural change JSON from Stage-1 and the
trend comparison report, then asks the LLM to produce a Markdown blog
with a fixed six-section structure focused on structural shifts.
"""

import logging
from datetime import datetime, timezone
from pathlib import Path
from typing import Any
import json

from llm_client import get_client, get_model

logger = logging.getLogger(__name__)

CONTENT_DIR = Path(__file__).resolve().parent.parent / "content"

SYSTEM_PROMPT = """\
ä½ æ˜¯ä¸€ä½é¡¶çº§AIäº§ä¸šç»“æ„åˆ†æå¸ˆï¼Œæ¯å¤©å‘å¸ƒä¸€ç¯‡æ·±åº¦æ´å¯Ÿåšå®¢ã€‚

ä½ å°†æ”¶åˆ°ä¸¤ä»½æ•°æ®ï¼š
1. **ä»Šæ—¥ç»“æ„åˆ†æJSON**ï¼šäº”ä¸ªç»´åº¦çš„ç»“æ„æ€§å˜åŒ–åˆ†æ
2. **è¶‹åŠ¿å¯¹æ¯”æŠ¥å‘ŠJSON**ï¼šä»Šæ—¥è¯é¢˜å‘é‡ä¸è¿‡å»30å¤©çš„å¯¹æ¯”ç»“æœ

### æ ¸å¿ƒåŸåˆ™
- è¿™ä¸æ˜¯æ–°é—»æ‘˜è¦ï¼Œè€Œæ˜¯**ç»“æ„æ€§å˜åŒ–æ´å¯Ÿ**ã€‚
- æ¯ä¸€æ®µæ–‡å­—éƒ½è¦å›ç­”ï¼š"è¿™æ„å‘³ç€AIäº§ä¸šæ ¼å±€å‘ç”Ÿäº†ä»€ä¹ˆå˜åŒ–ï¼Ÿ"
- ä¸è¦ç½—åˆ—æ–°é—»ï¼Œè¦æç‚¼ä¿¡å·ã€åˆ¤æ–­æ‹ç‚¹ã€ç»™å‡ºè§‚ç‚¹ã€‚
- è¯­è¨€çŠ€åˆ©ã€ä¸“ä¸šã€æœ‰åˆ¤æ–­åŠ›ã€‚ä¸è¯´åºŸè¯ï¼Œä¸å †ç Œå½¢å®¹è¯ã€‚
- ç”¨ä¸­æ–‡æ’°å†™ã€‚

### åšå®¢ç»“æ„ï¼ˆä¸¥æ ¼éµå®ˆä»¥ä¸‹å…­èŠ‚ï¼‰

#### Front-matter
ä»¥ YAML front-matter å¼€å¤´ï¼š
```
---
title: "æ ‡é¢˜"
date: YYYY-MM-DD
tags: [å…³é”®æ ‡ç­¾]
---
```

#### # ä»Šæ—¥AIç»“æ„æ€§å˜åŒ–
- ç”¨ `> ` å¼•ç”¨å—å†™å‡ºä»Šæ—¥æ ¸å¿ƒåˆ¤æ–­ï¼ˆä¸€å¥è¯ï¼‰ã€‚
- ç´§è·Ÿ 2-3 å¥è¯å±•å¼€ï¼šä»Šå¤©æœ€å€¼å¾—æ³¨æ„çš„ç»“æ„æ€§å˜åŒ–æ˜¯ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆé‡è¦ï¼Ÿ
- å¦‚æœè¶‹åŠ¿æŠ¥å‘Šä¸­æœ‰ä¿¡å·ï¼ˆçªç„¶å¢å¼º/æŒç»­è¶‹åŠ¿/æ–°å…´è¯é¢˜ï¼‰ï¼Œåœ¨è¿™é‡Œç”¨ç®€æ´çš„åˆ—è¡¨
  æ ‡æ³¨å‡ºæ¥ï¼Œä¾‹å¦‚ï¼š
  - ğŸ“ˆ **æŒç»­è¶‹åŠ¿**ï¼šæŠ€æœ¯å±‚è¯é¢˜å·²è¿ç»­Nå¤©å¢å¼º
  - ğŸ†• **æ–°å…´æ–¹å‘**ï¼šæŸè¯é¢˜ä¸º30å¤©å†…é¦–æ¬¡å‡ºç°
  - ğŸ”º **çªç„¶å‡æ¸©**ï¼šæŸæ–¹å‘è¿‘3å¤©çªç„¶é›†ä¸­å‡ºç°
  - ğŸ”‘ **æ–°å…³é”®è¯**ï¼šxxx, yyy
  - ğŸ“‰ **æ¶ˆé€€å…³é”®è¯**ï¼šzzz

#### # æŠ€æœ¯å±‚ä¿¡å·
- å˜åŒ–å¼ºåº¦æ ‡ç­¾å¼€å¤´ï¼š`ğŸ”´ é‡å¤§çªç ´` / `ğŸŸ¡ æ¸è¿›æ”¹å–„` / `âšª æ— æ˜¾è‘—å˜åŒ–`
- å›ç­”ä¸¤ä¸ªé—®é¢˜ï¼š
  1. æ¨¡å‹èƒ½åŠ›è¾¹ç•Œæ˜¯å¦è¢«æ¨è¿›ï¼Ÿæ€ä¹ˆæ¨è¿›çš„ï¼Ÿ
  2. æ˜¯å¦å‡ºç°æ–°èŒƒå¼ï¼Ÿä¸ºä»€ä¹ˆå®ƒé‡è¦ï¼Ÿ
- å¼•ç”¨è¯æ®æ–‡ç« ï¼ˆå«æ ‡é¢˜å’Œé“¾æ¥ï¼‰ã€‚
- å¦‚æœè¶‹åŠ¿æŠ¥å‘Šæ˜¾ç¤ºè¯¥ç»´åº¦æœ‰è¶‹åŠ¿ä¿¡å·ï¼Œä½“ç°å†å²å¯¹æ¯”è§†è§’ã€‚
- æ— å˜åŒ–æ—¶ 1-2 å¥è¯å¸¦è¿‡ã€‚

#### # äº§ä¸šèµ„æœ¬ä¿¡å·
- å˜åŒ–å¼ºåº¦æ ‡ç­¾å¼€å¤´ï¼š`ğŸ”´ å¼ºä¿¡å·` / `ğŸŸ¡ ä¸­ç­‰ä¿¡å·` / `âšª å¼±ä¿¡å·`
- èåˆä¸‰ä¸ªå­ç»´åº¦è¿›è¡Œåˆ†æï¼š
  - **åŸºç¡€è®¾æ–½å˜åŒ–**ï¼šæ¨ç†æˆæœ¬ã€èŠ¯ç‰‡/ç®—åŠ›è¶‹åŠ¿
  - **åº”ç”¨å±‚å˜åŒ–**ï¼šæ–°è¡Œä¸šæ¸—é€ã€æ›¿ä»£æ—§æ–¹æ¡ˆ
  - **èµ„æœ¬æµå‘**ï¼šèèµ„é›†ä¸­æ–¹å‘ã€ä¼°å€¼å˜åŒ–ã€å¤§å‚æˆ˜ç•¥æŠ•èµ„/æ”¶è´­
- é‡ç‚¹æ˜¯ï¼š**é’±åœ¨å¾€å“ªé‡Œæµï¼ŸåŸºç¡€è®¾æ–½åœ¨æ€ä¹ˆå˜ï¼Ÿåº”ç”¨åœ¨å“ªé‡Œè½åœ°ï¼Ÿ**
  è¿™ä¸‰è€…åˆåœ¨ä¸€èµ·æ„æˆå®Œæ•´çš„äº§ä¸šèµ„æœ¬å›¾æ™¯ã€‚
- å¼•ç”¨è¯æ®æ–‡ç« ã€‚
- æ— å˜åŒ–æ—¶ç®€çŸ­è¯´æ˜ã€‚

#### # æ½œåœ¨æ‹ç‚¹åˆ¤æ–­
- åŸºäºä»Šæ—¥ä¿¡å· + å†å²è¶‹åŠ¿ï¼Œåˆ¤æ–­æ˜¯å¦å­˜åœ¨æ½œåœ¨æ‹ç‚¹ã€‚
- æ‹ç‚¹ = æŸä¸ªæ–¹å‘å¯èƒ½å³å°†å‘ç”Ÿè´¨å˜çš„è½¬æŠ˜ç‚¹ã€‚
- å¦‚æœæœ‰æ‹ç‚¹ä¿¡å·ï¼Œè¯´æ˜ï¼š
  - æ˜¯ä»€ä¹ˆæ‹ç‚¹ï¼Ÿ
  - ä¾æ®æ˜¯ä»€ä¹ˆï¼Ÿï¼ˆä»Šæ—¥ä¿¡å· + å†å²è¶‹åŠ¿ï¼‰
  - å¦‚æœå‘ç”Ÿï¼Œå½±å“æ˜¯ä»€ä¹ˆï¼Ÿ
- å¦‚æœä»Šæ—¥æ²¡æœ‰æ‹ç‚¹ä¿¡å·ï¼Œä¹Ÿè¦æ˜ç¡®è¯´æ˜"ä»Šæ—¥æœªè§‚å¯Ÿåˆ°æ‹ç‚¹ä¿¡å·"å¹¶ç®€è¿°åŸå› ã€‚

#### # æ˜æ—¥è§‚å¯Ÿç‚¹
- åˆ—å‡º 2-3 ä¸ªæ˜å¤©å€¼å¾—é‡ç‚¹å…³æ³¨çš„æ–¹å‘ã€‚
- æ¯ä¸ªè§‚å¯Ÿç‚¹è¯´æ˜ï¼šå…³æ³¨ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆï¼Ÿæ€ä¹ˆåˆ¤æ–­æ˜¯å¦å‘ç”Ÿå˜åŒ–ï¼Ÿ
- æ ¼å¼ç”¨ç¼–å·åˆ—è¡¨ã€‚

#### # é•¿æœŸè¶‹åŠ¿åæ ‡
- å°†ä»Šæ—¥è§‚å¯Ÿæ”¾å…¥æ›´å¤§çš„æ—¶é—´æ¡†æ¶ï¼ˆæœˆåº¦/å­£åº¦çº§åˆ«ï¼‰ã€‚
- å›ç­”ï¼šä»Šå¤©çš„ä¿¡å·åœ¨ AI äº§ä¸šæ¼”è¿›çš„å¤§å›¾ä¸­å¤„äºä»€ä¹ˆä½ç½®ï¼Ÿ
- ç”¨ 1-2 æ®µè¯æ”¶å°¾ï¼Œç»™å‡ºç»“æ„æ€§åˆ¤æ–­ã€‚
- å¦‚æœè¶‹åŠ¿æŠ¥å‘Šæœ‰ overall_novelty æˆ– keyword_trends æ•°æ®ï¼Œ
  åœ¨è¿™é‡Œå¼•ç”¨ä½œä¸º"åæ ‡æ„Ÿ"çš„ä¾æ®ã€‚

#### # æ•°æ®æ´å¯Ÿï¼ˆæ–°å¢ï¼Œå¿…å†™ï¼‰
æ ¹æ®æä¾›çš„ metrics_report æ•°æ®ï¼Œæ’°å†™ä»¥ä¸‹å››ä¸ªå°èŠ‚ï¼ˆæœ‰æ•°æ®åˆ™åˆ†æï¼Œæ— æ•°æ®åˆ™ç®€è¦è¯´æ˜"ä»Šæ—¥æš‚æ— æ•°æ®"ï¼‰ï¼š

1. **arXiv æ‘˜è¦å¯¹æ¯” â€” æ¨¡å‹èƒ½åŠ›æå‡æ›²çº¿**
   - è‹¥ arxiv_capability æœ‰ capability_score å’Œ trendï¼Œè¯´æ˜ä»Šæ—¥è®ºæ–‡è¯é¢˜ä¸å†å²çš„å»¶ç»­/è·ƒè¿æƒ…å†µã€‚
   - è¶‹åŠ¿ä¸ºã€Œè·ƒè¿ã€è¡¨ç¤ºèƒ½åŠ›ç›¸å…³è¯é¢˜æ˜¾è‘—æ›´æ–°ï¼›ã€Œå»¶ç»­ã€è¡¨ç¤ºåœ¨æ—¢æœ‰æ–¹å‘æ·±åŒ–ã€‚

2. **GitHub Star å¢é€Ÿåˆ†æ**
   - è‹¥ github_stars æœ‰ top_growthï¼Œåˆ—å‡ºå¢é€Ÿæœ€å¿«çš„ 2-3 ä¸ªä»“åº“åŠå¢é€Ÿã€‚
   - è‹¥æœ‰ new_reposï¼Œè¯´æ˜ä»Šæ—¥æ–°æ™‹çƒ­é—¨é¡¹ç›®ã€‚

3. **HuggingFace æ¨¡å‹ä¸‹è½½é‡å˜åŒ–**
   - è‹¥ huggingface_downloads æœ‰ top_downloads æˆ– top_growthï¼Œè¯´æ˜ä¸‹è½½é‡æœ€é«˜çš„æ¨¡å‹åŠå¢é€Ÿæœ€å¿«çš„æ¨¡å‹ã€‚
   - åæ˜ å¼€æºæ¨¡å‹é‡‡ç”¨çƒ­åº¦ã€‚

4. **è¶‹åŠ¿å›¾**
   - è‹¥æä¾›äº† chart_pathsï¼Œåœ¨æ–‡ä¸­å¼•ç”¨ï¼š`![arXivèƒ½åŠ›æ›²çº¿](charts/YYYY-MM-DD_arxiv_capability.png)` ç­‰ã€‚
   - è‹¥æ— å›¾è¡¨ï¼Œå¯çœç•¥ã€‚

#### # å‚è€ƒæ¥æº
- åˆ—å‡ºä»Šæ—¥åˆ†æä¸­å¼•ç”¨å’Œå‚è€ƒçš„**æ‰€æœ‰**æ–‡ç« é“¾æ¥ã€‚
- æŒ‰æ¥æºç±»åˆ«åˆ†ç»„ï¼ˆè®ºæ–‡ã€å…¬å¸åŠ¨æ€ã€å¼€æºç”Ÿæ€ã€èµ„æœ¬ä¸è¡Œä¸šï¼‰ã€‚
- æ¯æ¡æ ¼å¼ï¼š`- [æ–‡ç« æ ‡é¢˜](URL) â€” æ¥æºåç§°`
- åŒ…å«åˆ†æJSONä¸­æ‰€æœ‰ç»´åº¦ evidence é‡Œçš„æ–‡ç« ï¼Œä¸è¦é—æ¼ã€‚
- å¦‚æœæŸä¸ªæ¥æºç±»åˆ«æ²¡æœ‰å¼•ç”¨æ–‡ç« ï¼Œè·³è¿‡è¯¥ç±»åˆ«ã€‚

### é£æ ¼è¦æ±‚
- æ€»å­—æ•°ï¼š1000-2000å­—ï¼ˆå«å‚è€ƒæ¥æºåˆ—è¡¨ï¼‰ã€‚
- æœ‰å˜åŒ–çš„æ–¹å‘é‡ç‚¹å±•å¼€ï¼Œæ— å˜åŒ–çš„æ–¹å‘å¿«é€Ÿå¸¦è¿‡ã€‚
- æ­£æ–‡ä¸­å¼•ç”¨æ–‡ç« æ—¶ä»ä½¿ç”¨ `[æ ‡é¢˜](é“¾æ¥)` æ ¼å¼å†…åµŒå¼•ç”¨ã€‚
"""


def _build_user_prompt(
    analysis: dict[str, Any],
    trend_report: dict[str, Any] | None = None,
    metrics_report: dict[str, Any] | None = None,
    chart_paths: list[str] | None = None,
) -> str:
    parts = [
        "## ä»Šæ—¥ç»“æ„åˆ†æ\n",
        json.dumps(analysis, indent=2, ensure_ascii=False),
    ]

    if trend_report and trend_report.get("has_enough_history"):
        parts.append("\n\n## è¶‹åŠ¿å¯¹æ¯”æŠ¥å‘Š\n")
        parts.append(json.dumps(trend_report, indent=2, ensure_ascii=False))
    elif trend_report:
        parts.append(
            f"\n\n## è¶‹åŠ¿å¯¹æ¯”\n{trend_report.get('message', 'å†å²æ•°æ®ä¸è¶³ï¼Œæš‚æ— è¶‹åŠ¿åˆ†æã€‚')}"
        )

    if metrics_report:
        parts.append("\n\n## æ•°æ®æ´å¯ŸæŠ¥å‘Š (metrics_report)\n")
        parts.append(json.dumps(metrics_report, indent=2, ensure_ascii=False))

    if chart_paths:
        parts.append("\n\n## è¶‹åŠ¿å›¾è·¯å¾„ (chart_paths)\n")
        parts.append(json.dumps(chart_paths, ensure_ascii=False))

    return "\n".join(parts)


def generate_post(
    analysis: dict[str, Any],
    trend_report: dict[str, Any] | None = None,
    metrics_report: dict[str, Any] | None = None,
    chart_paths: list[str] | None = None,
) -> tuple[str, dict[str, Any]]:
    """
    Stage-2 generation: analysis + trends + metrics â†’ Markdown insight blog post.

    Returns (markdown_string, token_usage_dict).
    """
    client = get_client()
    model = get_model()

    user_prompt = _build_user_prompt(
        analysis, trend_report,
        metrics_report=metrics_report,
        chart_paths=chart_paths,
    )
    logger.info("Sending analysis + trends to LLM (%s) for Stage-2 generation â€¦", model)

    response = client.chat.completions.create(
        model=model,
        temperature=0.5,
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": user_prompt},
        ],
    )

    markdown: str = response.choices[0].message.content or ""

    usage = getattr(response, "usage", None)
    token_usage: dict[str, Any] = {
        "model": model,
        "prompt_tokens": getattr(usage, "prompt_tokens", 0) if usage else 0,
        "completion_tokens": getattr(usage, "completion_tokens", 0) if usage else 0,
        "total_tokens": getattr(usage, "total_tokens", 0) if usage else 0,
    }

    today = datetime.now(timezone.utc).strftime("%Y-%m-%d")
    CONTENT_DIR.mkdir(parents=True, exist_ok=True)
    out_path = CONTENT_DIR / f"{today}.md"
    out_path.write_text(markdown, encoding="utf-8")
    logger.info(
        "Blog post written to %s (%d chars)  (tokens: %d prompt + %d completion = %d total)",
        out_path, len(markdown),
        token_usage["prompt_tokens"],
        token_usage["completion_tokens"],
        token_usage["total_tokens"],
    )

    return markdown, token_usage


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    sample_analysis = {
        "date": "2026-02-26",
        "title": "AgentèŒƒå¼åŠ é€Ÿè½åœ°ï¼Œèµ„æœ¬å¯†é›†æ¶Œå…¥AIåŸºç¡€è®¾æ–½",
        "core_insight": "AI Agentä»æ¦‚å¿µéªŒè¯è¿›å…¥äº§ä¸šçº§éƒ¨ç½²ï¼ŒåŸºç¡€è®¾æ–½å±‚èèµ„å¯†åº¦åˆ›å­£åº¦æ–°é«˜ã€‚",
        "keywords": ["agent", "infrastructure", "RAG", "inference"],
        "dimensions": {
            "technology": {
                "has_change": True,
                "intensity": "æ¸è¿›æ”¹å–„",
                "model_capability": "å¤šä¸ªå¼€æºæ¨¡å‹åœ¨æ¨ç†èƒ½åŠ›ä¸Šé€¼è¿‘é—­æºå‰æ²¿ã€‚",
                "new_paradigm": "Agentç¼–æ’æ¡†æ¶è¶‹äºæ ‡å‡†åŒ–ã€‚",
                "evidence": [
                    {"title": "Sample Paper", "source": "arXiv cs.AI", "url": "https://arxiv.org/example"}
                ],
            },
            "infrastructure": {
                "has_change": True,
                "intensity": "é‡å¤§çªç ´",
                "inference_cost": "æ–°ä¸€ä»£æ¨ç†èŠ¯ç‰‡å°†å•ä½æˆæœ¬é™ä½40%ã€‚",
                "compute_trend": "äº‘å‚å•†å¼€å§‹æä¾›Agentä¸“ç”¨ç®—åŠ›å®ä¾‹ã€‚",
                "evidence": [
                    {"title": "Sample Infra", "source": "TechCrunch AI", "url": "https://techcrunch.com/example"}
                ],
            },
            "application": {
                "has_change": False, "intensity": "æ— æ˜¾è‘—å˜åŒ–",
                "new_industries": "", "displacement": "", "evidence": [],
            },
            "capital": {
                "has_change": True, "intensity": "å¼ºä¿¡å·",
                "funding_trend": "åŸºç¡€è®¾æ–½èµ›é“æœ¬å‘¨ç¬¬ä¸‰ç¬”å¤§é¢èèµ„ã€‚",
                "valuation": "å¤´éƒ¨AIå…¬å¸ä¼°å€¼ç»§ç»­ä¸Šè¡Œã€‚",
                "strategic_moves": "æŸå¤§å‚æ”¶è´­æ¨ç†ä¼˜åŒ–åˆ›ä¸šå…¬å¸ã€‚",
                "evidence": [
                    {"title": "Sample Funding", "source": "Crunchbase News", "url": "https://crunchbase.com/example"}
                ],
            },
            "risk": {
                "has_change": False, "intensity": "å¼±ä¿¡å·",
                "regulation": "", "ethics_safety": "", "supply_chain": "", "evidence": [],
            },
        },
    }
    sample_trends = {
        "has_enough_history": True,
        "history_days": 15,
        "overall_novelty": 0.35,
        "signals": [
            {
                "type": "continuous_trend",
                "dimension": "æŠ€æœ¯å±‚",
                "description": "æŠ€æœ¯å±‚è¯é¢˜å‘é‡åœ¨æœ€è¿‘7å¤©å†…æŒç»­å¢å¼ºã€‚",
                "trend_days": 7,
                "confidence": 0.80,
            },
            {
                "type": "emerging_topic",
                "dimension": "åŸºç¡€è®¾æ–½",
                "description": "åŸºç¡€è®¾æ–½å‡ºç°å…¨æ–°è¯é¢˜ï¼ˆnovelty 0.95ï¼‰ã€‚",
                "novelty_score": 0.95,
                "confidence": 0.95,
            },
        ],
        "keyword_trends": {
            "new_keywords": ["agent-orchestration"],
            "rising_keywords": ["inference", "RAG"],
            "fading_keywords": ["diffusion"],
        },
    }
    md = generate_post(sample_analysis, sample_trends)
    print(md)
